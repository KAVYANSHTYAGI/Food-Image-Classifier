{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX2uRbCBOlOuNs94ewlP98",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAVYANSHTYAGI/Food-Image-Classifier/blob/main/novel_architecture_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RhdJ2Xvlzmr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau , LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AQRFBH_omAmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_dir_training = \"/content/drive/MyDrive/Food Image Datasets/North Indian/main_final/training\"\n",
        "class_labels_training = os.listdir(base_dir_training)\n",
        "print(len(class_labels_training))\n",
        "\n",
        "base_dir_testing = \"/content/drive/MyDrive/Food Image Datasets/North Indian/main_final/testing\"\n",
        "class_labels_testing = os.listdir(base_dir_testing)\n",
        "print(len(class_labels_testing))"
      ],
      "metadata": {
        "id": "l7oyWLadmC3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "\n",
        "data_training = []\n",
        "count = 0\n",
        "\n",
        "for label in class_labels_training:\n",
        "    path = os.path.join(base_dir_training, label)\n",
        "    print(path)\n",
        "    for img in os.listdir(path):\n",
        "        try:\n",
        "            image = load_img(os.path.join(path,img), color_mode=\"rgb\", target_size=(224,224))\n",
        "            image = img_to_array(image)\n",
        "            image /= 255.0\n",
        "            data_training.append([image, count])\n",
        "\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    count = count + 1\n",
        "\n",
        "#testing\n",
        "\n",
        "data_testing = []\n",
        "count = 0\n",
        "\n",
        "for label in class_labels_testing:\n",
        "    path = os.path.join(base_dir_testing, label)\n",
        "    print(path)\n",
        "    for img in os.listdir(path):\n",
        "        try:\n",
        "            image = load_img(os.path.join(path,img), color_mode=\"rgb\", target_size=(224,224))\n",
        "            image = img_to_array(image)\n",
        "            image /= 255.0\n",
        "            data_testing.append([image, count])\n",
        "\n",
        "        except Exception as e:\n",
        "            pass\n",
        "    count = count + 1\n"
      ],
      "metadata": {
        "id": "WqkzPocZmENq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data_training))\n",
        "print(len(data_testing))\n",
        "print(count)\n",
        "num_classes = count"
      ],
      "metadata": {
        "id": "-MOCEvZimYWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_train = zip(*data_training)\n",
        "\n",
        "x_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "\n",
        "X_test,y_test = zip(*data_testing)\n",
        "\n",
        "x_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "p7sIgVvhmGXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "pAu1u4PSmGU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'               # Fill missing pixels after transformations\n",
        ")\n",
        "\n",
        "\n",
        "val_test_datagen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow(x_train, y_train)\n",
        "val_generator = val_test_datagen.flow(x_test, y_test)"
      ],
      "metadata": {
        "id": "U4fToGqwmGSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "9FYSjeEzm72i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texture_input = layers.Input(shape=(224,224,3))\n",
        "texture_x = Conv2D(32, 3, activation='relu')(texture_input)\n",
        "texture_x = MaxPooling2D()(texture_x)\n",
        "\n",
        "# Adding CBAM Attention Module (Spatial + Channel)\n",
        "texture_x = cbam_block(texture_x)\n",
        "\n",
        "texture_x = Conv2D(64, 3, activation='relu')(texture_x)\n",
        "texture_x = GlobalAveragePooling2D()(texture_x)\n",
        "\n",
        "texture_branch_model = Model(inputs=texture_input, outputs=texture_x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "color_input = layers.Input(shape=(224,224,3))\n",
        "color_x = Conv2D(32, kernel_size=3, activation='relu')(color_input)\n",
        "color_x = MaxPooling2D()(color_x)\n",
        "\n",
        "# Channel Attention Module (SE Block)\n",
        "color_gap = GlobalAveragePooling2D()(color_x)\n",
        "color_attention = Dense(32//8, activation='relu')(color_x)\n",
        "color_attention = Dense(32, activation='sigmoid')(color_attention)\n",
        "color_x = Multiply()([color_x, color_attention])\n",
        "\n",
        "color_x = GlobalAveragePooling2D()(color_x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import vit\n",
        "structure_input = layers.Input(shape=(224,224,3))\n",
        "\n",
        "# ViT Small or Tiny pre-trained on ImageNet\n",
        "vit_model = vit.ViT_B16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "structure_x = vit_model(structure_input)\n",
        "structure_x = layers.GlobalAveragePooling1D()(structure_x)\n",
        "structure_branch_output = layers.Dense(256, activation='relu')(structure_x)\n"
      ],
      "metadata": {
        "id": "PvQzx3nim9Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_features = layers.Concatenate()([texture_x, color_x, structure_branch])\n",
        "\n",
        "# Attention-based fusion\n",
        "attention_features = layers.MultiHeadAttention(num_heads=4, key_dim=64)(\n",
        "    query=combined_features,\n",
        "    value=combined_features,\n",
        "    key=combined_features\n",
        ")\n",
        "\n",
        "attention_features = layers.GlobalAveragePooling1D()(attention_features)\n",
        "\n",
        "\n",
        "\n",
        "x = Dropout(0.4)(attention_features)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(30, activation='softmax')(x)\n",
        "\n",
        "final_model = Model(inputs=[texture_input, color_input, structure_input], outputs=output)\n"
      ],
      "metadata": {
        "id": "vGrZY5qBnFRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=40,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
        "    shuffle=True)\n",
        "\n",
        "# Plotting training and validation loss and accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xMp7uTe9mGQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, precision, recall, f1_score = model.evaluate(val_generator)\n",
        "print(f'test Loss: {loss}, test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "6AJG7WComGNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkXiA5YYmGLb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}